{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIkt4yxKpzgS"
   },
   "source": [
    "# CS 7643 Assignment 2 Part 2:  Implement and train a network on CIFAR-10 using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5eLeqVzpzgV"
   },
   "source": [
    "Convolutional Neural Networks (CNNs) are one of the major advancements in\n",
    "computer vision over the past decade. In this assignment, you will complete\n",
    "a simple CNN architecture from scratch and learn how to implement CNNs\n",
    "with PyTorch, one of the most commonly used deep learning frameworks.\n",
    "You will also run different experiments on imbalanced datasets to evaluate\n",
    "your model and techniques to deal with imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx3nM2xMpzgW"
   },
   "source": [
    "# Setup Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l86tglWzpzgX"
   },
   "source": [
    "Before getting started we need to run some standard code to set up our environment. You'll need to execute this code again each time you start the notebook.\n",
    "\n",
    "First, run this cell to load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This enables us to modify `.py` source files and reintegrate them into the notebook, ensuring a smooth editing and debugging experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j22uun9OpzgX",
    "ExecuteTime": {
     "end_time": "2025-10-01T08:54:20.751946Z",
     "start_time": "2025-10-01T08:54:20.658636Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pOTy-9dpzgY"
   },
   "source": [
    "### Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zujgqHl3pzgZ",
    "ExecuteTime": {
     "end_time": "2025-10-01T08:54:20.881311Z",
     "start_time": "2025-10-01T08:54:20.757293Z"
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgoogle\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcolab\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[32m      2\u001B[39m drive.mount(\u001B[33m'\u001B[39m\u001B[33m/content/drive\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'google'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAQYM7TWpzgZ"
   },
   "source": [
    "Now remember the path in your Google Drive where you uploaded this notebook, fill it in below. If all functions properly, executing the next cell should display the filenames from the assignment:\n",
    "\n",
    "```\n",
    "['CS7643-Assignment2-2.ipynb', 'cs7643', 'checkpoints', 'losses', 'configs', 'models', 'tests']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UiGZhhG8pzga"
   },
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded assignment1\n",
    "# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\n",
    "GOOGLE_DRIVE_PATH_POST_MYDRIVE = None\n",
    "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svKml_u_mwNn"
   },
   "source": [
    "### Local Setup or Google Colab\n",
    "Run the cell below regardless of setup to set the path "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "itp51CmXmy03",
    "ExecuteTime": {
     "end_time": "2025-10-01T08:54:24.733419Z",
     "start_time": "2025-10-01T08:54:24.711379Z"
    }
   },
   "source": [
    "# if running locally set GOOGLE PATH\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
    "else:\n",
    "  GOOGLE_DRIVE_PATH = '.'\n",
    "  print('Running locally.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C48GISpDpzga"
   },
   "source": [
    "After successfully mounting your Google Drive and identifying the path to this assignment, execute the following cell to enable us to import from the `.py` files of this assignment. If it works correctly, it should print the message (note, you may need to retry this twice if it fails):\n",
    "\n",
    "```\n",
    "Roger that from cnn.py!\n",
    "Roger that from my_model.py!\n",
    "Roger that from resnet.py!\n",
    "Roger that from twolayer.py!\n",
    "\n",
    "Roger that from focal_loss.py!\n",
    "```\n",
    "\n",
    "as well as the last edit time for the files `cnn.py`, `my_model.py`, `resnet.py`, `twolayer.py`, and `focal_loss.py`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QeqHoG1Dpzga",
    "ExecuteTime": {
     "end_time": "2025-10-01T08:54:25.858748Z",
     "start_time": "2025-10-01T08:54:25.707035Z"
    }
   },
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "from cs7643.env_prob import say_hello_do_you_copy\n",
    "\n",
    "say_hello_do_you_copy(GOOGLE_DRIVE_PATH)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Models ------------------\n",
      "Roger that from cnn.py!\n",
      "Roger that from my_model.py!\n",
      "Roger that from resnet.py!\n",
      "Roger that from twolayer.py!\n",
      "cnn.py last edited on Tue Sep 30 17:41:45 2025\n",
      "my_model.py last edited on Wed Oct  1 01:53:45 2025\n",
      "resnet.py last edited on Tue Aug 20 19:54:45 2024\n",
      "twolayer.py last edited on Tue Sep 30 11:21:35 2025\n",
      "\n",
      "---------- Losses ------------------\n",
      "Roger that from focal_loss.py!\n",
      "focal_loss.py last edited on Tue Sep 30 14:43:53 2025\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rev2Ozk1KGj3"
   },
   "source": [
    "# Load the CIFAR10 dataset\n",
    "Data loading is the very first step of any machine learning pipelines. Run the following cell to download the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kHlccnRMKXTw",
    "ExecuteTime": {
     "end_time": "2025-10-01T08:54:27.599741Z",
     "start_time": "2025-10-01T08:54:26.600564Z"
    }
   },
   "source": [
    "from cs7643.cifar10 import CIFAR10\n",
    "\n",
    "cifar10_ds = CIFAR10(GOOGLE_DRIVE_PATH + '/data/cifar10', download=True, train=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf2FgYgT3W03"
   },
   "source": [
    "We will use GPUs to accelerate our computation in this notebook. Run the following to make sure GPUs are enabled:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kuHZ057d3Uwx",
    "ExecuteTime": {
     "end_time": "2025-10-01T08:54:30.107410Z",
     "start_time": "2025-10-01T08:54:30.061804Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device = \" + device)\n",
    "if device == 'cpu':\n",
    "    print(\"WARNING: Using CPU will cause slower train times\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = mps\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tgfHDh0pzgb"
   },
   "source": [
    "# Training\n",
    "The first thing of working with PyTorch is to get yourself familiarized with\n",
    "the basic training step of PyTorch. Read through the [PyTorch Tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html) and complete __compute_loss_update_params_ function in `./solver.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuL2J65znk9R"
   },
   "source": [
    "## PyTorch Model\n",
    "You will now implement some actual networks with PyTorch. We provide\n",
    "some starter files for you in `./models`. The models for you to implement are\n",
    "as follows:\n",
    "\n",
    "* **Two-Layer Network**. This is the same network you have implemented from scratch in assignment 1. You will build the model with two fully connected layers and a sigmoid activation function in between the two layers. Please implement the model as instructed in `./models/twolayer.py`.\n",
    "\n",
    "* **Vanilla Convolutional Neural Network**. You will build the model with a\n",
    "convolution layer, a ReLU activation, a max-pooling layer, followed by a fully connected layer for classification. Your convolution layer should use **32 output channels**, a **kernel size of 7** with **stride 1** and **zero padding**. You max-pooling should use a **kernel size of 2** and **stride of 2**. The fully connected layer should have **10 output features**. Please implement the model as instructed in `./models/cnn.py`.\n",
    "\n",
    "* Your Own Network. You are now free to build your own model. Notice that it's okay for you to borrow some insights from existing well-known networks, however, directly using those networks as-is is **NOT** allowed.\n",
    "In other words, you have to build your model from scratch, which also means using any sort of pre-trained weights is also **NOT** allowed. Please implement your model in `./models/my_model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgEN4027oF9j"
   },
   "source": [
    "We provide you configuration files for these three models respectively. For\n",
    "Two-Layer Network and Vanilla CNN, you need to train the model without modifying the configuration file. The script automatically saves the weights of the best model at the end of training. We will evaluate your implementation by loading your model weights and evaluating the model on CIFAR-10 test data. You should expect the accuracy of Two-Layer Network and Vanilla CNN to be around 0.3 and 0.4 respectively.\n",
    "\n",
    "For your own network, you are free to tune any hyper-parameters to\n",
    "obtain better accuracy. Your final accuracy must be above 0.5 to receive\n",
    "at least partial credit. Please refer to the GradeScope auto-test results\n",
    "for the requirement of full credits. Try to keep your submission **under\n",
    "100mb or GradeScope may not accept it**. All in all, please make sure\n",
    "the checkpoints of each model are saved into `./checkpoints`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbYkRflMMQR-"
   },
   "source": [
    "Select a configuration file from the list then run the cell to train your model. To select a custom config, select \"Show code\" and specify the path to your config file. **Note that you may have to restart the jupyter kernel after updating the files above before running the below snippet.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "G4HceY6Fy2vx",
    "ExecuteTime": {
     "end_time": "2025-10-01T09:04:23.096267Z",
     "start_time": "2025-10-01T08:54:32.215104Z"
    }
   },
   "source": [
    "import yaml\n",
    "from solver import Solver\n",
    "\n",
    "config_file = \"config_mymodel\" # feel free to change to  [\"config_mymodel\", \"config_twolayer\", \"config_vanilla_cnn\", or other]\n",
    "\n",
    "config_file = GOOGLE_DRIVE_PATH + \"/configs/\" + config_file + \".yaml\"\n",
    "\n",
    "print(\"Training a model using configuration file \" + config_file)\n",
    "\n",
    "with open(config_file, \"r\") as read_file:\n",
    "  config = yaml.safe_load(read_file)\n",
    "\n",
    "kwargs = {}\n",
    "for key in config:\n",
    "  for k, v in config[key].items():\n",
    "    if k != 'description':\n",
    "      kwargs[k] = v\n",
    "\n",
    "kwargs['device'] = device\n",
    "kwargs['path_prefix'] = GOOGLE_DRIVE_PATH\n",
    "\n",
    "print(kwargs)\n",
    "\n",
    "solver = Solver(**kwargs)\n",
    "solver.train()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a model using configuration file ./configs/config_mymodel.yaml\n",
      "{'batch_size': 128, 'learning_rate': 0.0001, 'reg': 0.0005, 'epochs': 10, 'steps': [6, 8], 'warmup': 0, 'momentum': 0.9, 'gamma': 1, 'model': 'MyModel', 'imbalance': 'regular', 'save_best': True, 'loss_type': 'CE', 'device': 'mps', 'path_prefix': '.'}\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MyModel(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avg): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch: [0][0/391]\tTime 0.434 (0.434)\tLoss 2.4072 (2.4072)\tPrec @1 0.1094 (0.1094)\t\n",
      "Epoch: [0][10/391]\tTime 0.075 (0.108)\tLoss 2.3573 (2.3934)\tPrec @1 0.1016 (0.0980)\t\n",
      "Epoch: [0][20/391]\tTime 0.076 (0.092)\tLoss 2.3239 (2.3786)\tPrec @1 0.2031 (0.1090)\t\n",
      "Epoch: [0][30/391]\tTime 0.072 (0.086)\tLoss 2.2889 (2.3564)\tPrec @1 0.1484 (0.1225)\t\n",
      "Epoch: [0][40/391]\tTime 0.072 (0.083)\tLoss 2.2365 (2.3274)\tPrec @1 0.2266 (0.1406)\t\n",
      "Epoch: [0][50/391]\tTime 0.073 (0.081)\tLoss 2.1956 (2.3019)\tPrec @1 0.2344 (0.1595)\t\n",
      "Epoch: [0][60/391]\tTime 0.073 (0.080)\tLoss 2.1151 (2.2799)\tPrec @1 0.3047 (0.1729)\t\n",
      "Epoch: [0][70/391]\tTime 0.078 (0.079)\tLoss 2.1217 (2.2617)\tPrec @1 0.2891 (0.1851)\t\n",
      "Epoch: [0][80/391]\tTime 0.084 (0.079)\tLoss 2.1038 (2.2463)\tPrec @1 0.2656 (0.1910)\t\n",
      "Epoch: [0][90/391]\tTime 0.073 (0.079)\tLoss 2.0931 (2.2341)\tPrec @1 0.2031 (0.1945)\t\n",
      "Epoch: [0][100/391]\tTime 0.076 (0.079)\tLoss 2.0932 (2.2209)\tPrec @1 0.2578 (0.2005)\t\n",
      "Epoch: [0][110/391]\tTime 0.074 (0.078)\tLoss 2.1156 (2.2082)\tPrec @1 0.2422 (0.2067)\t\n",
      "Epoch: [0][120/391]\tTime 0.085 (0.078)\tLoss 2.0719 (2.1973)\tPrec @1 0.2266 (0.2092)\t\n",
      "Epoch: [0][130/391]\tTime 0.090 (0.078)\tLoss 2.0829 (2.1855)\tPrec @1 0.2734 (0.2132)\t\n",
      "Epoch: [0][140/391]\tTime 0.074 (0.079)\tLoss 2.0587 (2.1751)\tPrec @1 0.2188 (0.2173)\t\n",
      "Epoch: [0][150/391]\tTime 0.074 (0.079)\tLoss 1.9730 (2.1645)\tPrec @1 0.2969 (0.2215)\t\n",
      "Epoch: [0][160/391]\tTime 0.073 (0.078)\tLoss 1.9751 (2.1549)\tPrec @1 0.3516 (0.2247)\t\n",
      "Epoch: [0][170/391]\tTime 0.072 (0.078)\tLoss 2.0294 (2.1477)\tPrec @1 0.2422 (0.2273)\t\n",
      "Epoch: [0][180/391]\tTime 0.078 (0.078)\tLoss 2.0080 (2.1383)\tPrec @1 0.3203 (0.2317)\t\n",
      "Epoch: [0][190/391]\tTime 0.075 (0.079)\tLoss 1.8625 (2.1291)\tPrec @1 0.3828 (0.2353)\t\n",
      "Epoch: [0][200/391]\tTime 0.074 (0.079)\tLoss 1.9974 (2.1220)\tPrec @1 0.2578 (0.2369)\t\n",
      "Epoch: [0][210/391]\tTime 0.072 (0.078)\tLoss 2.0044 (2.1148)\tPrec @1 0.2812 (0.2389)\t\n",
      "Epoch: [0][220/391]\tTime 0.072 (0.078)\tLoss 1.9281 (2.1069)\tPrec @1 0.2969 (0.2417)\t\n",
      "Epoch: [0][230/391]\tTime 0.075 (0.078)\tLoss 1.9594 (2.1000)\tPrec @1 0.2969 (0.2449)\t\n",
      "Epoch: [0][240/391]\tTime 0.070 (0.078)\tLoss 1.9399 (2.0937)\tPrec @1 0.3047 (0.2469)\t\n",
      "Epoch: [0][250/391]\tTime 0.073 (0.078)\tLoss 1.8942 (2.0862)\tPrec @1 0.3438 (0.2502)\t\n",
      "Epoch: [0][260/391]\tTime 0.072 (0.078)\tLoss 1.9676 (2.0808)\tPrec @1 0.2891 (0.2525)\t\n",
      "Epoch: [0][270/391]\tTime 0.070 (0.077)\tLoss 1.8790 (2.0749)\tPrec @1 0.3828 (0.2548)\t\n",
      "Epoch: [0][280/391]\tTime 0.071 (0.077)\tLoss 1.9138 (2.0692)\tPrec @1 0.3203 (0.2559)\t\n",
      "Epoch: [0][290/391]\tTime 0.073 (0.077)\tLoss 1.9232 (2.0632)\tPrec @1 0.3672 (0.2577)\t\n",
      "Epoch: [0][300/391]\tTime 0.072 (0.077)\tLoss 1.9459 (2.0581)\tPrec @1 0.3438 (0.2598)\t\n",
      "Epoch: [0][310/391]\tTime 0.073 (0.077)\tLoss 1.8673 (2.0528)\tPrec @1 0.3438 (0.2621)\t\n",
      "Epoch: [0][320/391]\tTime 0.072 (0.077)\tLoss 1.9078 (2.0479)\tPrec @1 0.3594 (0.2638)\t\n",
      "Epoch: [0][330/391]\tTime 0.072 (0.077)\tLoss 1.8032 (2.0424)\tPrec @1 0.3359 (0.2657)\t\n",
      "Epoch: [0][340/391]\tTime 0.071 (0.077)\tLoss 1.7956 (2.0371)\tPrec @1 0.3594 (0.2675)\t\n",
      "Epoch: [0][350/391]\tTime 0.074 (0.077)\tLoss 1.8443 (2.0328)\tPrec @1 0.3984 (0.2685)\t\n",
      "Epoch: [0][360/391]\tTime 0.075 (0.077)\tLoss 1.8478 (2.0282)\tPrec @1 0.3516 (0.2708)\t\n",
      "Epoch: [0][370/391]\tTime 0.071 (0.077)\tLoss 1.8722 (2.0236)\tPrec @1 0.3203 (0.2729)\t\n",
      "Epoch: [0][380/391]\tTime 0.071 (0.077)\tLoss 1.7753 (2.0192)\tPrec @1 0.4688 (0.2747)\t\n",
      "Epoch: [0][390/391]\tTime 0.159 (0.077)\tLoss 1.9967 (2.0157)\tPrec @1 0.2750 (0.2760)\t\n",
      "Epoch: [0][0/100]\tTime 0.204 (0.204)\t\n",
      "Epoch: [0][10/100]\tTime 0.113 (0.114)\t\n",
      "Epoch: [0][20/100]\tTime 0.094 (0.107)\t\n",
      "Epoch: [0][30/100]\tTime 0.109 (0.106)\t\n",
      "Epoch: [0][40/100]\tTime 0.113 (0.108)\t\n",
      "Epoch: [0][50/100]\tTime 0.121 (0.109)\t\n",
      "Epoch: [0][60/100]\tTime 0.104 (0.109)\t\n",
      "Epoch: [0][70/100]\tTime 0.119 (0.108)\t\n",
      "Epoch: [0][80/100]\tTime 0.089 (0.107)\t\n",
      "Epoch: [0][90/100]\tTime 0.095 (0.108)\t\n",
      "Accuracy of Class 0: 0.3430\n",
      "Accuracy of Class 1: 0.3770\n",
      "Accuracy of Class 2: 0.2130\n",
      "Accuracy of Class 3: 0.1260\n",
      "Accuracy of Class 4: 0.4090\n",
      "Accuracy of Class 5: 0.2930\n",
      "Accuracy of Class 6: 0.5290\n",
      "Accuracy of Class 7: 0.1570\n",
      "Accuracy of Class 8: 0.6470\n",
      "Accuracy of Class 9: 0.2640\n",
      "* Prec @1: 0.3358\n",
      "Epoch: [1][0/391]\tTime 0.112 (0.112)\tLoss 1.8853 (1.8853)\tPrec @1 0.3750 (0.3750)\t\n",
      "Epoch: [1][10/391]\tTime 0.075 (0.078)\tLoss 1.8156 (1.8405)\tPrec @1 0.3359 (0.3480)\t\n",
      "Epoch: [1][20/391]\tTime 0.071 (0.076)\tLoss 1.8002 (1.8392)\tPrec @1 0.3672 (0.3464)\t\n",
      "Epoch: [1][30/391]\tTime 0.075 (0.075)\tLoss 1.7709 (1.8421)\tPrec @1 0.3984 (0.3485)\t\n",
      "Epoch: [1][40/391]\tTime 0.071 (0.075)\tLoss 1.7868 (1.8353)\tPrec @1 0.3359 (0.3500)\t\n",
      "Epoch: [1][50/391]\tTime 0.071 (0.075)\tLoss 1.8516 (1.8337)\tPrec @1 0.3516 (0.3500)\t\n",
      "Epoch: [1][60/391]\tTime 0.075 (0.075)\tLoss 1.7914 (1.8312)\tPrec @1 0.3516 (0.3470)\t\n",
      "Epoch: [1][70/391]\tTime 0.074 (0.075)\tLoss 1.7972 (1.8276)\tPrec @1 0.3047 (0.3461)\t\n",
      "Epoch: [1][80/391]\tTime 0.068 (0.075)\tLoss 1.8249 (1.8242)\tPrec @1 0.3516 (0.3473)\t\n",
      "Epoch: [1][90/391]\tTime 0.068 (0.075)\tLoss 1.8055 (1.8217)\tPrec @1 0.3359 (0.3488)\t\n",
      "Epoch: [1][100/391]\tTime 0.073 (0.075)\tLoss 1.7018 (1.8201)\tPrec @1 0.3516 (0.3480)\t\n",
      "Epoch: [1][110/391]\tTime 0.072 (0.075)\tLoss 1.8226 (1.8175)\tPrec @1 0.3125 (0.3495)\t\n",
      "Epoch: [1][120/391]\tTime 0.076 (0.075)\tLoss 1.8387 (1.8160)\tPrec @1 0.3281 (0.3503)\t\n",
      "Epoch: [1][130/391]\tTime 0.071 (0.075)\tLoss 1.8200 (1.8124)\tPrec @1 0.4062 (0.3523)\t\n",
      "Epoch: [1][140/391]\tTime 0.071 (0.075)\tLoss 1.8259 (1.8099)\tPrec @1 0.2734 (0.3527)\t\n",
      "Epoch: [1][150/391]\tTime 0.072 (0.075)\tLoss 1.7688 (1.8090)\tPrec @1 0.3984 (0.3541)\t\n",
      "Epoch: [1][160/391]\tTime 0.076 (0.075)\tLoss 1.8344 (1.8076)\tPrec @1 0.3828 (0.3554)\t\n",
      "Epoch: [1][170/391]\tTime 0.075 (0.075)\tLoss 1.7025 (1.8062)\tPrec @1 0.3594 (0.3547)\t\n",
      "Epoch: [1][180/391]\tTime 0.076 (0.075)\tLoss 1.7942 (1.8058)\tPrec @1 0.3516 (0.3556)\t\n",
      "Epoch: [1][190/391]\tTime 0.078 (0.075)\tLoss 1.7423 (1.8065)\tPrec @1 0.3203 (0.3555)\t\n",
      "Epoch: [1][200/391]\tTime 0.073 (0.075)\tLoss 1.7997 (1.8042)\tPrec @1 0.3438 (0.3564)\t\n",
      "Epoch: [1][210/391]\tTime 0.096 (0.076)\tLoss 1.6537 (1.8002)\tPrec @1 0.3750 (0.3576)\t\n",
      "Epoch: [1][220/391]\tTime 0.157 (0.077)\tLoss 1.8219 (1.7982)\tPrec @1 0.3672 (0.3585)\t\n",
      "Epoch: [1][230/391]\tTime 0.085 (0.078)\tLoss 1.7511 (1.7965)\tPrec @1 0.3672 (0.3590)\t\n",
      "Epoch: [1][240/391]\tTime 0.085 (0.079)\tLoss 1.7567 (1.7939)\tPrec @1 0.3203 (0.3602)\t\n",
      "Epoch: [1][250/391]\tTime 0.073 (0.079)\tLoss 1.7688 (1.7909)\tPrec @1 0.3906 (0.3616)\t\n",
      "Epoch: [1][260/391]\tTime 0.073 (0.078)\tLoss 1.7672 (1.7884)\tPrec @1 0.4453 (0.3622)\t\n",
      "Epoch: [1][270/391]\tTime 0.074 (0.078)\tLoss 1.6865 (1.7863)\tPrec @1 0.4062 (0.3632)\t\n",
      "Epoch: [1][280/391]\tTime 0.073 (0.078)\tLoss 1.7401 (1.7845)\tPrec @1 0.3906 (0.3642)\t\n",
      "Epoch: [1][290/391]\tTime 0.074 (0.078)\tLoss 1.7558 (1.7819)\tPrec @1 0.3906 (0.3657)\t\n",
      "Epoch: [1][300/391]\tTime 0.077 (0.078)\tLoss 1.6398 (1.7802)\tPrec @1 0.3672 (0.3666)\t\n",
      "Epoch: [1][310/391]\tTime 0.072 (0.078)\tLoss 1.6574 (1.7781)\tPrec @1 0.4375 (0.3672)\t\n",
      "Epoch: [1][320/391]\tTime 0.073 (0.078)\tLoss 1.6805 (1.7757)\tPrec @1 0.3516 (0.3679)\t\n",
      "Epoch: [1][330/391]\tTime 0.073 (0.078)\tLoss 1.6253 (1.7737)\tPrec @1 0.3984 (0.3684)\t\n",
      "Epoch: [1][340/391]\tTime 0.075 (0.078)\tLoss 1.6574 (1.7726)\tPrec @1 0.4297 (0.3688)\t\n",
      "Epoch: [1][350/391]\tTime 0.073 (0.078)\tLoss 1.7401 (1.7704)\tPrec @1 0.3672 (0.3691)\t\n",
      "Epoch: [1][360/391]\tTime 0.071 (0.077)\tLoss 1.6204 (1.7670)\tPrec @1 0.4219 (0.3705)\t\n",
      "Epoch: [1][370/391]\tTime 0.075 (0.077)\tLoss 1.6753 (1.7639)\tPrec @1 0.3906 (0.3714)\t\n",
      "Epoch: [1][380/391]\tTime 0.076 (0.077)\tLoss 1.7129 (1.7626)\tPrec @1 0.3672 (0.3718)\t\n",
      "Epoch: [1][390/391]\tTime 0.050 (0.077)\tLoss 1.7306 (1.7620)\tPrec @1 0.3750 (0.3714)\t\n",
      "Epoch: [1][0/100]\tTime 0.178 (0.178)\t\n",
      "Epoch: [1][10/100]\tTime 0.106 (0.103)\t\n",
      "Epoch: [1][20/100]\tTime 0.104 (0.100)\t\n",
      "Epoch: [1][30/100]\tTime 0.088 (0.099)\t\n",
      "Epoch: [1][40/100]\tTime 0.090 (0.099)\t\n",
      "Epoch: [1][50/100]\tTime 0.099 (0.100)\t\n",
      "Epoch: [1][60/100]\tTime 0.112 (0.100)\t\n",
      "Epoch: [1][70/100]\tTime 0.106 (0.099)\t\n",
      "Epoch: [1][80/100]\tTime 0.090 (0.099)\t\n",
      "Epoch: [1][90/100]\tTime 0.087 (0.099)\t\n",
      "Accuracy of Class 0: 0.4170\n",
      "Accuracy of Class 1: 0.4220\n",
      "Accuracy of Class 2: 0.2040\n",
      "Accuracy of Class 3: 0.1300\n",
      "Accuracy of Class 4: 0.4140\n",
      "Accuracy of Class 5: 0.4900\n",
      "Accuracy of Class 6: 0.5450\n",
      "Accuracy of Class 7: 0.2420\n",
      "Accuracy of Class 8: 0.6740\n",
      "Accuracy of Class 9: 0.4140\n",
      "* Prec @1: 0.3952\n",
      "Epoch: [2][0/391]\tTime 0.112 (0.112)\tLoss 1.6955 (1.6955)\tPrec @1 0.3984 (0.3984)\t\n",
      "Epoch: [2][10/391]\tTime 0.073 (0.078)\tLoss 1.6774 (1.6886)\tPrec @1 0.4219 (0.4091)\t\n",
      "Epoch: [2][20/391]\tTime 0.074 (0.076)\tLoss 1.6538 (1.6770)\tPrec @1 0.4531 (0.4156)\t\n",
      "Epoch: [2][30/391]\tTime 0.070 (0.075)\tLoss 1.7212 (1.6781)\tPrec @1 0.4062 (0.4100)\t\n",
      "Epoch: [2][40/391]\tTime 0.072 (0.075)\tLoss 1.6333 (1.6773)\tPrec @1 0.4766 (0.4143)\t\n",
      "Epoch: [2][50/391]\tTime 0.074 (0.075)\tLoss 1.6195 (1.6776)\tPrec @1 0.4375 (0.4124)\t\n",
      "Epoch: [2][60/391]\tTime 0.071 (0.075)\tLoss 1.7023 (1.6741)\tPrec @1 0.4062 (0.4109)\t\n",
      "Epoch: [2][70/391]\tTime 0.070 (0.074)\tLoss 1.6676 (1.6761)\tPrec @1 0.4453 (0.4087)\t\n",
      "Epoch: [2][80/391]\tTime 0.070 (0.074)\tLoss 1.6659 (1.6747)\tPrec @1 0.3828 (0.4075)\t\n",
      "Epoch: [2][90/391]\tTime 0.072 (0.074)\tLoss 1.6175 (1.6743)\tPrec @1 0.4219 (0.4077)\t\n",
      "Epoch: [2][100/391]\tTime 0.072 (0.074)\tLoss 1.6089 (1.6740)\tPrec @1 0.4453 (0.4045)\t\n",
      "Epoch: [2][110/391]\tTime 0.075 (0.074)\tLoss 1.5795 (1.6683)\tPrec @1 0.4297 (0.4067)\t\n",
      "Epoch: [2][120/391]\tTime 0.074 (0.075)\tLoss 1.6500 (1.6657)\tPrec @1 0.4453 (0.4078)\t\n",
      "Epoch: [2][130/391]\tTime 0.075 (0.074)\tLoss 1.6564 (1.6676)\tPrec @1 0.4062 (0.4069)\t\n",
      "Epoch: [2][140/391]\tTime 0.076 (0.074)\tLoss 1.6093 (1.6665)\tPrec @1 0.4453 (0.4073)\t\n",
      "Epoch: [2][150/391]\tTime 0.075 (0.074)\tLoss 1.6300 (1.6648)\tPrec @1 0.4219 (0.4082)\t\n",
      "Epoch: [2][160/391]\tTime 0.070 (0.074)\tLoss 1.6369 (1.6644)\tPrec @1 0.4062 (0.4075)\t\n",
      "Epoch: [2][170/391]\tTime 0.072 (0.074)\tLoss 1.6299 (1.6615)\tPrec @1 0.3750 (0.4085)\t\n",
      "Epoch: [2][180/391]\tTime 0.073 (0.074)\tLoss 1.7420 (1.6601)\tPrec @1 0.3672 (0.4084)\t\n",
      "Epoch: [2][190/391]\tTime 0.075 (0.074)\tLoss 1.6863 (1.6603)\tPrec @1 0.3828 (0.4093)\t\n",
      "Epoch: [2][200/391]\tTime 0.074 (0.074)\tLoss 1.7028 (1.6591)\tPrec @1 0.3828 (0.4097)\t\n",
      "Epoch: [2][210/391]\tTime 0.085 (0.074)\tLoss 1.6615 (1.6577)\tPrec @1 0.3906 (0.4095)\t\n",
      "Epoch: [2][220/391]\tTime 0.076 (0.074)\tLoss 1.7104 (1.6571)\tPrec @1 0.3672 (0.4098)\t\n",
      "Epoch: [2][230/391]\tTime 0.076 (0.074)\tLoss 1.6109 (1.6553)\tPrec @1 0.4141 (0.4105)\t\n",
      "Epoch: [2][240/391]\tTime 0.074 (0.074)\tLoss 1.6103 (1.6527)\tPrec @1 0.3828 (0.4112)\t\n",
      "Epoch: [2][250/391]\tTime 0.073 (0.074)\tLoss 1.5530 (1.6513)\tPrec @1 0.4219 (0.4110)\t\n",
      "Epoch: [2][260/391]\tTime 0.073 (0.074)\tLoss 1.5729 (1.6486)\tPrec @1 0.4609 (0.4116)\t\n",
      "Epoch: [2][270/391]\tTime 0.073 (0.074)\tLoss 1.6195 (1.6474)\tPrec @1 0.4375 (0.4131)\t\n",
      "Epoch: [2][280/391]\tTime 0.077 (0.075)\tLoss 1.6517 (1.6457)\tPrec @1 0.3750 (0.4138)\t\n",
      "Epoch: [2][290/391]\tTime 0.062 (0.075)\tLoss 1.5130 (1.6438)\tPrec @1 0.4453 (0.4152)\t\n",
      "Epoch: [2][300/391]\tTime 0.062 (0.075)\tLoss 1.6679 (1.6418)\tPrec @1 0.3750 (0.4161)\t\n",
      "Epoch: [2][310/391]\tTime 0.077 (0.075)\tLoss 1.5807 (1.6401)\tPrec @1 0.3984 (0.4158)\t\n",
      "Epoch: [2][320/391]\tTime 0.075 (0.075)\tLoss 1.5938 (1.6384)\tPrec @1 0.4297 (0.4164)\t\n",
      "Epoch: [2][330/391]\tTime 0.082 (0.075)\tLoss 1.5985 (1.6374)\tPrec @1 0.4141 (0.4169)\t\n",
      "Epoch: [2][340/391]\tTime 0.080 (0.075)\tLoss 1.5437 (1.6359)\tPrec @1 0.4766 (0.4171)\t\n",
      "Epoch: [2][350/391]\tTime 0.063 (0.075)\tLoss 1.5335 (1.6344)\tPrec @1 0.4062 (0.4178)\t\n",
      "Epoch: [2][360/391]\tTime 0.067 (0.075)\tLoss 1.6533 (1.6335)\tPrec @1 0.3984 (0.4184)\t\n",
      "Epoch: [2][370/391]\tTime 0.085 (0.075)\tLoss 1.5822 (1.6319)\tPrec @1 0.5156 (0.4185)\t\n",
      "Epoch: [2][380/391]\tTime 0.064 (0.075)\tLoss 1.4528 (1.6311)\tPrec @1 0.5156 (0.4191)\t\n",
      "Epoch: [2][390/391]\tTime 0.038 (0.075)\tLoss 1.4103 (1.6299)\tPrec @1 0.5125 (0.4192)\t\n",
      "Epoch: [2][0/100]\tTime 0.147 (0.147)\t\n",
      "Epoch: [2][10/100]\tTime 0.094 (0.108)\t\n",
      "Epoch: [2][20/100]\tTime 0.101 (0.104)\t\n",
      "Epoch: [2][30/100]\tTime 0.090 (0.104)\t\n",
      "Epoch: [2][40/100]\tTime 0.101 (0.104)\t\n",
      "Epoch: [2][50/100]\tTime 0.118 (0.103)\t\n",
      "Epoch: [2][60/100]\tTime 0.087 (0.101)\t\n",
      "Epoch: [2][70/100]\tTime 0.087 (0.101)\t\n",
      "Epoch: [2][80/100]\tTime 0.110 (0.100)\t\n",
      "Epoch: [2][90/100]\tTime 0.090 (0.100)\t\n",
      "Accuracy of Class 0: 0.4410\n",
      "Accuracy of Class 1: 0.4760\n",
      "Accuracy of Class 2: 0.2980\n",
      "Accuracy of Class 3: 0.1240\n",
      "Accuracy of Class 4: 0.3620\n",
      "Accuracy of Class 5: 0.5890\n",
      "Accuracy of Class 6: 0.5840\n",
      "Accuracy of Class 7: 0.3390\n",
      "Accuracy of Class 8: 0.6800\n",
      "Accuracy of Class 9: 0.3830\n",
      "* Prec @1: 0.4276\n",
      "Epoch: [3][0/391]\tTime 0.108 (0.108)\tLoss 1.5400 (1.5400)\tPrec @1 0.4219 (0.4219)\t\n",
      "Epoch: [3][10/391]\tTime 0.075 (0.078)\tLoss 1.6029 (1.5770)\tPrec @1 0.3984 (0.4311)\t\n",
      "Epoch: [3][20/391]\tTime 0.071 (0.076)\tLoss 1.5787 (1.5782)\tPrec @1 0.4453 (0.4382)\t\n",
      "Epoch: [3][30/391]\tTime 0.070 (0.075)\tLoss 1.5871 (1.5757)\tPrec @1 0.4453 (0.4430)\t\n",
      "Epoch: [3][40/391]\tTime 0.071 (0.075)\tLoss 1.4810 (1.5752)\tPrec @1 0.4922 (0.4421)\t\n",
      "Epoch: [3][50/391]\tTime 0.073 (0.074)\tLoss 1.5521 (1.5734)\tPrec @1 0.4375 (0.4410)\t\n",
      "Epoch: [3][60/391]\tTime 0.072 (0.074)\tLoss 1.5053 (1.5761)\tPrec @1 0.4219 (0.4412)\t\n",
      "Epoch: [3][70/391]\tTime 0.072 (0.074)\tLoss 1.6382 (1.5729)\tPrec @1 0.3828 (0.4426)\t\n",
      "Epoch: [3][80/391]\tTime 0.070 (0.074)\tLoss 1.5937 (1.5717)\tPrec @1 0.4531 (0.4434)\t\n",
      "Epoch: [3][90/391]\tTime 0.075 (0.074)\tLoss 1.5145 (1.5694)\tPrec @1 0.3984 (0.4428)\t\n",
      "Epoch: [3][100/391]\tTime 0.070 (0.074)\tLoss 1.5060 (1.5645)\tPrec @1 0.4766 (0.4455)\t\n",
      "Epoch: [3][110/391]\tTime 0.075 (0.074)\tLoss 1.5702 (1.5629)\tPrec @1 0.4766 (0.4443)\t\n",
      "Epoch: [3][120/391]\tTime 0.077 (0.075)\tLoss 1.6397 (1.5615)\tPrec @1 0.3984 (0.4458)\t\n",
      "Epoch: [3][130/391]\tTime 0.071 (0.075)\tLoss 1.5435 (1.5613)\tPrec @1 0.4297 (0.4442)\t\n",
      "Epoch: [3][140/391]\tTime 0.072 (0.075)\tLoss 1.4940 (1.5623)\tPrec @1 0.4219 (0.4427)\t\n",
      "Epoch: [3][150/391]\tTime 0.074 (0.075)\tLoss 1.4926 (1.5592)\tPrec @1 0.4766 (0.4442)\t\n",
      "Epoch: [3][160/391]\tTime 0.071 (0.075)\tLoss 1.4628 (1.5560)\tPrec @1 0.5000 (0.4455)\t\n",
      "Epoch: [3][170/391]\tTime 0.076 (0.075)\tLoss 1.4666 (1.5537)\tPrec @1 0.4609 (0.4458)\t\n",
      "Epoch: [3][180/391]\tTime 0.073 (0.075)\tLoss 1.5485 (1.5535)\tPrec @1 0.4609 (0.4461)\t\n",
      "Epoch: [3][190/391]\tTime 0.075 (0.075)\tLoss 1.6562 (1.5527)\tPrec @1 0.3906 (0.4463)\t\n",
      "Epoch: [3][200/391]\tTime 0.072 (0.075)\tLoss 1.5679 (1.5523)\tPrec @1 0.4688 (0.4468)\t\n",
      "Epoch: [3][210/391]\tTime 0.073 (0.075)\tLoss 1.6300 (1.5531)\tPrec @1 0.3906 (0.4465)\t\n",
      "Epoch: [3][220/391]\tTime 0.071 (0.075)\tLoss 1.6431 (1.5521)\tPrec @1 0.3672 (0.4474)\t\n",
      "Epoch: [3][230/391]\tTime 0.085 (0.075)\tLoss 1.5015 (1.5509)\tPrec @1 0.4531 (0.4473)\t\n",
      "Epoch: [3][240/391]\tTime 0.104 (0.075)\tLoss 1.5998 (1.5508)\tPrec @1 0.4219 (0.4471)\t\n",
      "Epoch: [3][250/391]\tTime 0.093 (0.076)\tLoss 1.6735 (1.5502)\tPrec @1 0.3984 (0.4479)\t\n",
      "Epoch: [3][260/391]\tTime 0.073 (0.076)\tLoss 1.6473 (1.5494)\tPrec @1 0.3906 (0.4482)\t\n",
      "Epoch: [3][270/391]\tTime 0.072 (0.076)\tLoss 1.4889 (1.5485)\tPrec @1 0.4219 (0.4487)\t\n",
      "Epoch: [3][280/391]\tTime 0.072 (0.076)\tLoss 1.4870 (1.5471)\tPrec @1 0.5547 (0.4496)\t\n",
      "Epoch: [3][290/391]\tTime 0.079 (0.076)\tLoss 1.5054 (1.5465)\tPrec @1 0.4766 (0.4500)\t\n",
      "Epoch: [3][300/391]\tTime 0.074 (0.076)\tLoss 1.6146 (1.5459)\tPrec @1 0.4375 (0.4503)\t\n",
      "Epoch: [3][310/391]\tTime 0.081 (0.076)\tLoss 1.5029 (1.5453)\tPrec @1 0.4922 (0.4507)\t\n",
      "Epoch: [3][320/391]\tTime 0.071 (0.076)\tLoss 1.4587 (1.5442)\tPrec @1 0.4688 (0.4509)\t\n",
      "Epoch: [3][330/391]\tTime 0.072 (0.076)\tLoss 1.4415 (1.5434)\tPrec @1 0.4844 (0.4514)\t\n",
      "Epoch: [3][340/391]\tTime 0.073 (0.076)\tLoss 1.5821 (1.5433)\tPrec @1 0.4531 (0.4510)\t\n",
      "Epoch: [3][350/391]\tTime 0.071 (0.076)\tLoss 1.4391 (1.5413)\tPrec @1 0.5234 (0.4525)\t\n",
      "Epoch: [3][360/391]\tTime 0.074 (0.076)\tLoss 1.5749 (1.5408)\tPrec @1 0.4531 (0.4527)\t\n",
      "Epoch: [3][370/391]\tTime 0.075 (0.076)\tLoss 1.5059 (1.5401)\tPrec @1 0.4766 (0.4528)\t\n",
      "Epoch: [3][380/391]\tTime 0.073 (0.076)\tLoss 1.5513 (1.5396)\tPrec @1 0.4688 (0.4532)\t\n",
      "Epoch: [3][390/391]\tTime 0.053 (0.076)\tLoss 1.5137 (1.5384)\tPrec @1 0.4125 (0.4537)\t\n",
      "Epoch: [3][0/100]\tTime 0.168 (0.168)\t\n",
      "Epoch: [3][10/100]\tTime 0.096 (0.112)\t\n",
      "Epoch: [3][20/100]\tTime 0.103 (0.108)\t\n",
      "Epoch: [3][30/100]\tTime 0.093 (0.106)\t\n",
      "Epoch: [3][40/100]\tTime 0.089 (0.103)\t\n",
      "Epoch: [3][50/100]\tTime 0.110 (0.102)\t\n",
      "Epoch: [3][60/100]\tTime 0.089 (0.101)\t\n",
      "Epoch: [3][70/100]\tTime 0.089 (0.101)\t\n",
      "Epoch: [3][80/100]\tTime 0.097 (0.101)\t\n",
      "Epoch: [3][90/100]\tTime 0.092 (0.101)\t\n",
      "Accuracy of Class 0: 0.4410\n",
      "Accuracy of Class 1: 0.5060\n",
      "Accuracy of Class 2: 0.3060\n",
      "Accuracy of Class 3: 0.1360\n",
      "Accuracy of Class 4: 0.2930\n",
      "Accuracy of Class 5: 0.6420\n",
      "Accuracy of Class 6: 0.6650\n",
      "Accuracy of Class 7: 0.4260\n",
      "Accuracy of Class 8: 0.7110\n",
      "Accuracy of Class 9: 0.4600\n",
      "* Prec @1: 0.4586\n",
      "Epoch: [4][0/391]\tTime 0.103 (0.103)\tLoss 1.5439 (1.5439)\tPrec @1 0.4375 (0.4375)\t\n",
      "Epoch: [4][10/391]\tTime 0.069 (0.077)\tLoss 1.5161 (1.5040)\tPrec @1 0.5078 (0.4716)\t\n",
      "Epoch: [4][20/391]\tTime 0.070 (0.076)\tLoss 1.3739 (1.4864)\tPrec @1 0.5391 (0.4758)\t\n",
      "Epoch: [4][30/391]\tTime 0.073 (0.075)\tLoss 1.5055 (1.4752)\tPrec @1 0.3906 (0.4758)\t\n",
      "Epoch: [4][40/391]\tTime 0.071 (0.075)\tLoss 1.4840 (1.4760)\tPrec @1 0.4609 (0.4785)\t\n",
      "Epoch: [4][50/391]\tTime 0.072 (0.075)\tLoss 1.4871 (1.4817)\tPrec @1 0.4766 (0.4758)\t\n",
      "Epoch: [4][60/391]\tTime 0.071 (0.075)\tLoss 1.4408 (1.4798)\tPrec @1 0.5547 (0.4762)\t\n",
      "Epoch: [4][70/391]\tTime 0.072 (0.074)\tLoss 1.4965 (1.4781)\tPrec @1 0.4531 (0.4748)\t\n",
      "Epoch: [4][80/391]\tTime 0.072 (0.074)\tLoss 1.3857 (1.4723)\tPrec @1 0.5469 (0.4790)\t\n",
      "Epoch: [4][90/391]\tTime 0.070 (0.074)\tLoss 1.4020 (1.4681)\tPrec @1 0.5078 (0.4796)\t\n",
      "Epoch: [4][100/391]\tTime 0.071 (0.074)\tLoss 1.5482 (1.4731)\tPrec @1 0.4375 (0.4766)\t\n",
      "Epoch: [4][110/391]\tTime 0.072 (0.074)\tLoss 1.4280 (1.4740)\tPrec @1 0.4844 (0.4761)\t\n",
      "Epoch: [4][120/391]\tTime 0.073 (0.074)\tLoss 1.4932 (1.4756)\tPrec @1 0.4453 (0.4764)\t\n",
      "Epoch: [4][130/391]\tTime 0.076 (0.074)\tLoss 1.3182 (1.4759)\tPrec @1 0.5703 (0.4769)\t\n",
      "Epoch: [4][140/391]\tTime 0.073 (0.074)\tLoss 1.3882 (1.4756)\tPrec @1 0.6094 (0.4783)\t\n",
      "Epoch: [4][150/391]\tTime 0.076 (0.074)\tLoss 1.4240 (1.4750)\tPrec @1 0.4609 (0.4779)\t\n",
      "Epoch: [4][160/391]\tTime 0.072 (0.074)\tLoss 1.5534 (1.4759)\tPrec @1 0.3828 (0.4772)\t\n",
      "Epoch: [4][170/391]\tTime 0.073 (0.074)\tLoss 1.4566 (1.4770)\tPrec @1 0.4688 (0.4767)\t\n",
      "Epoch: [4][180/391]\tTime 0.075 (0.074)\tLoss 1.3446 (1.4768)\tPrec @1 0.4922 (0.4770)\t\n",
      "Epoch: [4][190/391]\tTime 0.073 (0.074)\tLoss 1.4811 (1.4762)\tPrec @1 0.4531 (0.4765)\t\n",
      "Epoch: [4][200/391]\tTime 0.072 (0.074)\tLoss 1.4317 (1.4747)\tPrec @1 0.4688 (0.4764)\t\n",
      "Epoch: [4][210/391]\tTime 0.075 (0.074)\tLoss 1.3615 (1.4742)\tPrec @1 0.5391 (0.4768)\t\n",
      "Epoch: [4][220/391]\tTime 0.075 (0.074)\tLoss 1.5170 (1.4730)\tPrec @1 0.4766 (0.4773)\t\n",
      "Epoch: [4][230/391]\tTime 0.075 (0.074)\tLoss 1.4941 (1.4713)\tPrec @1 0.4141 (0.4784)\t\n",
      "Epoch: [4][240/391]\tTime 0.076 (0.074)\tLoss 1.4081 (1.4702)\tPrec @1 0.5156 (0.4791)\t\n",
      "Epoch: [4][250/391]\tTime 0.070 (0.074)\tLoss 1.4281 (1.4699)\tPrec @1 0.4766 (0.4794)\t\n",
      "Epoch: [4][260/391]\tTime 0.081 (0.075)\tLoss 1.3266 (1.4691)\tPrec @1 0.5312 (0.4794)\t\n",
      "Epoch: [4][270/391]\tTime 0.082 (0.075)\tLoss 1.3378 (1.4684)\tPrec @1 0.5156 (0.4793)\t\n",
      "Epoch: [4][280/391]\tTime 0.069 (0.076)\tLoss 1.3860 (1.4682)\tPrec @1 0.5312 (0.4794)\t\n",
      "Epoch: [4][290/391]\tTime 0.064 (0.076)\tLoss 1.4233 (1.4672)\tPrec @1 0.4922 (0.4798)\t\n",
      "Epoch: [4][300/391]\tTime 0.063 (0.076)\tLoss 1.5147 (1.4663)\tPrec @1 0.4531 (0.4807)\t\n",
      "Epoch: [4][310/391]\tTime 0.082 (0.076)\tLoss 1.3913 (1.4660)\tPrec @1 0.5000 (0.4808)\t\n",
      "Epoch: [4][320/391]\tTime 0.064 (0.076)\tLoss 1.4534 (1.4653)\tPrec @1 0.4062 (0.4805)\t\n",
      "Epoch: [4][330/391]\tTime 0.092 (0.076)\tLoss 1.3856 (1.4648)\tPrec @1 0.4922 (0.4806)\t\n",
      "Epoch: [4][340/391]\tTime 0.062 (0.076)\tLoss 1.4094 (1.4640)\tPrec @1 0.5391 (0.4814)\t\n",
      "Epoch: [4][350/391]\tTime 0.076 (0.076)\tLoss 1.4338 (1.4634)\tPrec @1 0.4375 (0.4815)\t\n",
      "Epoch: [4][360/391]\tTime 0.071 (0.076)\tLoss 1.4400 (1.4617)\tPrec @1 0.5000 (0.4820)\t\n",
      "Epoch: [4][370/391]\tTime 0.082 (0.076)\tLoss 1.4858 (1.4613)\tPrec @1 0.4531 (0.4818)\t\n",
      "Epoch: [4][380/391]\tTime 0.066 (0.076)\tLoss 1.5878 (1.4609)\tPrec @1 0.4531 (0.4822)\t\n",
      "Epoch: [4][390/391]\tTime 0.052 (0.076)\tLoss 1.4856 (1.4598)\tPrec @1 0.5000 (0.4828)\t\n",
      "Epoch: [4][0/100]\tTime 0.180 (0.180)\t\n",
      "Epoch: [4][10/100]\tTime 0.107 (0.104)\t\n",
      "Epoch: [4][20/100]\tTime 0.120 (0.102)\t\n",
      "Epoch: [4][30/100]\tTime 0.095 (0.102)\t\n",
      "Epoch: [4][40/100]\tTime 0.095 (0.102)\t\n",
      "Epoch: [4][50/100]\tTime 0.102 (0.101)\t\n",
      "Epoch: [4][60/100]\tTime 0.090 (0.100)\t\n",
      "Epoch: [4][70/100]\tTime 0.107 (0.100)\t\n",
      "Epoch: [4][80/100]\tTime 0.111 (0.100)\t\n",
      "Epoch: [4][90/100]\tTime 0.094 (0.100)\t\n",
      "Accuracy of Class 0: 0.4070\n",
      "Accuracy of Class 1: 0.5840\n",
      "Accuracy of Class 2: 0.2980\n",
      "Accuracy of Class 3: 0.2200\n",
      "Accuracy of Class 4: 0.3350\n",
      "Accuracy of Class 5: 0.5380\n",
      "Accuracy of Class 6: 0.7520\n",
      "Accuracy of Class 7: 0.4730\n",
      "Accuracy of Class 8: 0.7610\n",
      "Accuracy of Class 9: 0.4500\n",
      "* Prec @1: 0.4818\n",
      "Epoch: [5][0/391]\tTime 0.101 (0.101)\tLoss 1.3903 (1.3903)\tPrec @1 0.4531 (0.4531)\t\n",
      "Epoch: [5][10/391]\tTime 0.070 (0.078)\tLoss 1.3948 (1.4297)\tPrec @1 0.4922 (0.4830)\t\n",
      "Epoch: [5][20/391]\tTime 0.076 (0.076)\tLoss 1.4286 (1.4182)\tPrec @1 0.5078 (0.4978)\t\n",
      "Epoch: [5][30/391]\tTime 0.075 (0.075)\tLoss 1.2786 (1.4135)\tPrec @1 0.5156 (0.4972)\t\n",
      "Epoch: [5][40/391]\tTime 0.073 (0.075)\tLoss 1.3584 (1.4180)\tPrec @1 0.5859 (0.4970)\t\n",
      "Epoch: [5][50/391]\tTime 0.070 (0.075)\tLoss 1.2586 (1.4151)\tPrec @1 0.5547 (0.4975)\t\n",
      "Epoch: [5][60/391]\tTime 0.072 (0.075)\tLoss 1.4922 (1.4085)\tPrec @1 0.5312 (0.5024)\t\n",
      "Epoch: [5][70/391]\tTime 0.074 (0.074)\tLoss 1.4070 (1.4140)\tPrec @1 0.5234 (0.4992)\t\n",
      "Epoch: [5][80/391]\tTime 0.073 (0.074)\tLoss 1.4842 (1.4132)\tPrec @1 0.4609 (0.4988)\t\n",
      "Epoch: [5][90/391]\tTime 0.074 (0.074)\tLoss 1.4403 (1.4135)\tPrec @1 0.4844 (0.4983)\t\n",
      "Epoch: [5][100/391]\tTime 0.073 (0.074)\tLoss 1.3958 (1.4122)\tPrec @1 0.5156 (0.4975)\t\n",
      "Epoch: [5][110/391]\tTime 0.074 (0.074)\tLoss 1.3976 (1.4082)\tPrec @1 0.5000 (0.4979)\t\n",
      "Epoch: [5][120/391]\tTime 0.071 (0.074)\tLoss 1.4741 (1.4073)\tPrec @1 0.4844 (0.4992)\t\n",
      "Epoch: [5][130/391]\tTime 0.069 (0.074)\tLoss 1.3757 (1.4077)\tPrec @1 0.5234 (0.4995)\t\n",
      "Epoch: [5][140/391]\tTime 0.074 (0.074)\tLoss 1.3193 (1.4101)\tPrec @1 0.5078 (0.4982)\t\n",
      "Epoch: [5][150/391]\tTime 0.071 (0.074)\tLoss 1.4623 (1.4095)\tPrec @1 0.4609 (0.4994)\t\n",
      "Epoch: [5][160/391]\tTime 0.072 (0.074)\tLoss 1.3319 (1.4093)\tPrec @1 0.4766 (0.4991)\t\n",
      "Epoch: [5][170/391]\tTime 0.072 (0.074)\tLoss 1.4263 (1.4094)\tPrec @1 0.4219 (0.4993)\t\n",
      "Epoch: [5][180/391]\tTime 0.073 (0.074)\tLoss 1.4230 (1.4087)\tPrec @1 0.5312 (0.5002)\t\n",
      "Epoch: [5][190/391]\tTime 0.072 (0.074)\tLoss 1.3417 (1.4055)\tPrec @1 0.5078 (0.5011)\t\n",
      "Epoch: [5][200/391]\tTime 0.072 (0.074)\tLoss 1.3880 (1.4057)\tPrec @1 0.5000 (0.5014)\t\n",
      "Epoch: [5][210/391]\tTime 0.074 (0.074)\tLoss 1.2996 (1.4046)\tPrec @1 0.5156 (0.5017)\t\n",
      "Epoch: [5][220/391]\tTime 0.072 (0.074)\tLoss 1.4682 (1.4036)\tPrec @1 0.5234 (0.5023)\t\n",
      "Epoch: [5][230/391]\tTime 0.059 (0.074)\tLoss 1.3819 (1.4034)\tPrec @1 0.5000 (0.5017)\t\n",
      "Epoch: [5][240/391]\tTime 0.071 (0.074)\tLoss 1.2425 (1.4021)\tPrec @1 0.5625 (0.5027)\t\n",
      "Epoch: [5][250/391]\tTime 0.073 (0.074)\tLoss 1.2988 (1.4023)\tPrec @1 0.5312 (0.5021)\t\n",
      "Epoch: [5][260/391]\tTime 0.077 (0.074)\tLoss 1.2768 (1.4011)\tPrec @1 0.5312 (0.5019)\t\n",
      "Epoch: [5][270/391]\tTime 0.078 (0.074)\tLoss 1.4274 (1.4007)\tPrec @1 0.4297 (0.5018)\t\n",
      "Epoch: [5][280/391]\tTime 0.084 (0.074)\tLoss 1.3393 (1.3993)\tPrec @1 0.5234 (0.5027)\t\n",
      "Epoch: [5][290/391]\tTime 0.062 (0.075)\tLoss 1.5550 (1.4001)\tPrec @1 0.4219 (0.5021)\t\n",
      "Epoch: [5][300/391]\tTime 0.059 (0.075)\tLoss 1.3228 (1.3993)\tPrec @1 0.5312 (0.5025)\t\n",
      "Epoch: [5][310/391]\tTime 0.067 (0.075)\tLoss 1.3516 (1.4006)\tPrec @1 0.5234 (0.5016)\t\n",
      "Epoch: [5][320/391]\tTime 0.063 (0.075)\tLoss 1.2809 (1.4002)\tPrec @1 0.5312 (0.5022)\t\n",
      "Epoch: [5][330/391]\tTime 0.073 (0.075)\tLoss 1.2366 (1.3990)\tPrec @1 0.5547 (0.5027)\t\n",
      "Epoch: [5][340/391]\tTime 0.062 (0.075)\tLoss 1.3996 (1.3980)\tPrec @1 0.4766 (0.5032)\t\n",
      "Epoch: [5][350/391]\tTime 0.087 (0.075)\tLoss 1.4301 (1.3981)\tPrec @1 0.5000 (0.5027)\t\n",
      "Epoch: [5][360/391]\tTime 0.066 (0.075)\tLoss 1.3064 (1.3976)\tPrec @1 0.6406 (0.5028)\t\n",
      "Epoch: [5][370/391]\tTime 0.060 (0.075)\tLoss 1.4155 (1.3972)\tPrec @1 0.4844 (0.5034)\t\n",
      "Epoch: [5][380/391]\tTime 0.085 (0.075)\tLoss 1.3539 (1.3967)\tPrec @1 0.4766 (0.5032)\t\n",
      "Epoch: [5][390/391]\tTime 0.041 (0.075)\tLoss 1.1973 (1.3956)\tPrec @1 0.6375 (0.5036)\t\n",
      "Epoch: [5][0/100]\tTime 0.143 (0.143)\t\n",
      "Epoch: [5][10/100]\tTime 0.114 (0.102)\t\n",
      "Epoch: [5][20/100]\tTime 0.092 (0.103)\t\n",
      "Epoch: [5][30/100]\tTime 0.090 (0.101)\t\n",
      "Epoch: [5][40/100]\tTime 0.106 (0.102)\t\n",
      "Epoch: [5][50/100]\tTime 0.092 (0.102)\t\n",
      "Epoch: [5][60/100]\tTime 0.085 (0.102)\t\n",
      "Epoch: [5][70/100]\tTime 0.087 (0.100)\t\n",
      "Epoch: [5][80/100]\tTime 0.091 (0.100)\t\n",
      "Epoch: [5][90/100]\tTime 0.098 (0.100)\t\n",
      "Accuracy of Class 0: 0.4640\n",
      "Accuracy of Class 1: 0.5970\n",
      "Accuracy of Class 2: 0.3180\n",
      "Accuracy of Class 3: 0.2330\n",
      "Accuracy of Class 4: 0.3110\n",
      "Accuracy of Class 5: 0.6210\n",
      "Accuracy of Class 6: 0.7490\n",
      "Accuracy of Class 7: 0.5010\n",
      "Accuracy of Class 8: 0.7670\n",
      "Accuracy of Class 9: 0.5150\n",
      "* Prec @1: 0.5076\n",
      "Epoch: [6][0/391]\tTime 0.105 (0.105)\tLoss 1.5000 (1.5000)\tPrec @1 0.5156 (0.5156)\t\n",
      "Epoch: [6][10/391]\tTime 0.072 (0.078)\tLoss 1.3783 (1.3982)\tPrec @1 0.5391 (0.5142)\t\n",
      "Epoch: [6][20/391]\tTime 0.073 (0.076)\tLoss 1.3879 (1.3883)\tPrec @1 0.4922 (0.5112)\t\n",
      "Epoch: [6][30/391]\tTime 0.072 (0.075)\tLoss 1.4225 (1.3844)\tPrec @1 0.5000 (0.5123)\t\n",
      "Epoch: [6][40/391]\tTime 0.074 (0.075)\tLoss 1.3363 (1.3804)\tPrec @1 0.5234 (0.5103)\t\n",
      "Epoch: [6][50/391]\tTime 0.074 (0.075)\tLoss 1.2362 (1.3724)\tPrec @1 0.5234 (0.5123)\t\n",
      "Epoch: [6][60/391]\tTime 0.072 (0.075)\tLoss 1.3820 (1.3705)\tPrec @1 0.5469 (0.5158)\t\n",
      "Epoch: [6][70/391]\tTime 0.075 (0.075)\tLoss 1.2732 (1.3621)\tPrec @1 0.5547 (0.5168)\t\n",
      "Epoch: [6][80/391]\tTime 0.074 (0.075)\tLoss 1.3703 (1.3684)\tPrec @1 0.5469 (0.5139)\t\n",
      "Epoch: [6][90/391]\tTime 0.072 (0.075)\tLoss 1.5252 (1.3661)\tPrec @1 0.4141 (0.5161)\t\n",
      "Epoch: [6][100/391]\tTime 0.071 (0.075)\tLoss 1.2428 (1.3632)\tPrec @1 0.5781 (0.5173)\t\n",
      "Epoch: [6][110/391]\tTime 0.072 (0.075)\tLoss 1.2743 (1.3619)\tPrec @1 0.5391 (0.5181)\t\n",
      "Epoch: [6][120/391]\tTime 0.071 (0.074)\tLoss 1.2577 (1.3600)\tPrec @1 0.6016 (0.5192)\t\n",
      "Epoch: [6][130/391]\tTime 0.070 (0.074)\tLoss 1.4389 (1.3597)\tPrec @1 0.5078 (0.5201)\t\n",
      "Epoch: [6][140/391]\tTime 0.073 (0.074)\tLoss 1.3677 (1.3599)\tPrec @1 0.4844 (0.5203)\t\n",
      "Epoch: [6][150/391]\tTime 0.079 (0.075)\tLoss 1.3265 (1.3625)\tPrec @1 0.5703 (0.5203)\t\n",
      "Epoch: [6][160/391]\tTime 0.075 (0.075)\tLoss 1.3557 (1.3626)\tPrec @1 0.5312 (0.5206)\t\n",
      "Epoch: [6][170/391]\tTime 0.075 (0.075)\tLoss 1.3137 (1.3610)\tPrec @1 0.5000 (0.5198)\t\n",
      "Epoch: [6][180/391]\tTime 0.073 (0.075)\tLoss 1.4229 (1.3607)\tPrec @1 0.4922 (0.5192)\t\n",
      "Epoch: [6][190/391]\tTime 0.073 (0.075)\tLoss 1.2940 (1.3612)\tPrec @1 0.5547 (0.5197)\t\n",
      "Epoch: [6][200/391]\tTime 0.077 (0.075)\tLoss 1.2544 (1.3624)\tPrec @1 0.5078 (0.5188)\t\n",
      "Epoch: [6][210/391]\tTime 0.073 (0.075)\tLoss 1.3474 (1.3626)\tPrec @1 0.5078 (0.5179)\t\n",
      "Epoch: [6][220/391]\tTime 0.074 (0.075)\tLoss 1.4066 (1.3636)\tPrec @1 0.5547 (0.5178)\t\n",
      "Epoch: [6][230/391]\tTime 0.073 (0.075)\tLoss 1.2815 (1.3622)\tPrec @1 0.5391 (0.5191)\t\n",
      "Epoch: [6][240/391]\tTime 0.075 (0.075)\tLoss 1.3599 (1.3633)\tPrec @1 0.5234 (0.5183)\t\n",
      "Epoch: [6][250/391]\tTime 0.075 (0.075)\tLoss 1.3023 (1.3631)\tPrec @1 0.5078 (0.5180)\t\n",
      "Epoch: [6][260/391]\tTime 0.073 (0.075)\tLoss 1.3662 (1.3619)\tPrec @1 0.5234 (0.5178)\t\n",
      "Epoch: [6][270/391]\tTime 0.073 (0.075)\tLoss 1.2869 (1.3610)\tPrec @1 0.5156 (0.5177)\t\n",
      "Epoch: [6][280/391]\tTime 0.076 (0.075)\tLoss 1.4075 (1.3620)\tPrec @1 0.5625 (0.5167)\t\n",
      "Epoch: [6][290/391]\tTime 0.073 (0.075)\tLoss 1.2555 (1.3620)\tPrec @1 0.5156 (0.5169)\t\n",
      "Epoch: [6][300/391]\tTime 0.074 (0.075)\tLoss 1.3313 (1.3601)\tPrec @1 0.5234 (0.5175)\t\n",
      "Epoch: [6][310/391]\tTime 0.079 (0.075)\tLoss 1.4109 (1.3600)\tPrec @1 0.5312 (0.5176)\t\n",
      "Epoch: [6][320/391]\tTime 0.075 (0.075)\tLoss 1.2766 (1.3612)\tPrec @1 0.5625 (0.5171)\t\n",
      "Epoch: [6][330/391]\tTime 0.077 (0.075)\tLoss 1.3037 (1.3609)\tPrec @1 0.5234 (0.5169)\t\n",
      "Epoch: [6][340/391]\tTime 0.077 (0.075)\tLoss 1.5149 (1.3612)\tPrec @1 0.4844 (0.5168)\t\n",
      "Epoch: [6][350/391]\tTime 0.067 (0.075)\tLoss 1.2914 (1.3608)\tPrec @1 0.5312 (0.5172)\t\n",
      "Epoch: [6][360/391]\tTime 0.063 (0.075)\tLoss 1.3391 (1.3599)\tPrec @1 0.5312 (0.5174)\t\n",
      "Epoch: [6][370/391]\tTime 0.060 (0.075)\tLoss 1.2544 (1.3596)\tPrec @1 0.5625 (0.5176)\t\n",
      "Epoch: [6][380/391]\tTime 0.081 (0.075)\tLoss 1.4479 (1.3597)\tPrec @1 0.4062 (0.5173)\t\n",
      "Epoch: [6][390/391]\tTime 0.049 (0.075)\tLoss 1.2769 (1.3595)\tPrec @1 0.5625 (0.5175)\t\n",
      "Epoch: [6][0/100]\tTime 0.159 (0.159)\t\n",
      "Epoch: [6][10/100]\tTime 0.110 (0.106)\t\n",
      "Epoch: [6][20/100]\tTime 0.091 (0.100)\t\n",
      "Epoch: [6][30/100]\tTime 0.090 (0.097)\t\n",
      "Epoch: [6][40/100]\tTime 0.095 (0.097)\t\n",
      "Epoch: [6][50/100]\tTime 0.099 (0.097)\t\n",
      "Epoch: [6][60/100]\tTime 0.089 (0.098)\t\n",
      "Epoch: [6][70/100]\tTime 0.091 (0.099)\t\n",
      "Epoch: [6][80/100]\tTime 0.088 (0.099)\t\n",
      "Epoch: [6][90/100]\tTime 0.086 (0.099)\t\n",
      "Accuracy of Class 0: 0.5010\n",
      "Accuracy of Class 1: 0.6060\n",
      "Accuracy of Class 2: 0.3470\n",
      "Accuracy of Class 3: 0.2230\n",
      "Accuracy of Class 4: 0.3340\n",
      "Accuracy of Class 5: 0.6240\n",
      "Accuracy of Class 6: 0.7350\n",
      "Accuracy of Class 7: 0.5650\n",
      "Accuracy of Class 8: 0.7060\n",
      "Accuracy of Class 9: 0.5400\n",
      "* Prec @1: 0.5181\n",
      "Epoch: [7][0/391]\tTime 0.112 (0.112)\tLoss 1.4408 (1.4408)\tPrec @1 0.4766 (0.4766)\t\n",
      "Epoch: [7][10/391]\tTime 0.074 (0.078)\tLoss 1.2565 (1.3405)\tPrec @1 0.5703 (0.5220)\t\n",
      "Epoch: [7][20/391]\tTime 0.072 (0.076)\tLoss 1.2692 (1.3289)\tPrec @1 0.5859 (0.5342)\t\n",
      "Epoch: [7][30/391]\tTime 0.072 (0.075)\tLoss 1.2264 (1.3344)\tPrec @1 0.5547 (0.5292)\t\n",
      "Epoch: [7][40/391]\tTime 0.074 (0.075)\tLoss 1.2857 (1.3393)\tPrec @1 0.5859 (0.5284)\t\n",
      "Epoch: [7][50/391]\tTime 0.076 (0.075)\tLoss 1.2955 (1.3410)\tPrec @1 0.5078 (0.5314)\t\n",
      "Epoch: [7][60/391]\tTime 0.073 (0.075)\tLoss 1.3595 (1.3404)\tPrec @1 0.5312 (0.5309)\t\n",
      "Epoch: [7][70/391]\tTime 0.073 (0.075)\tLoss 1.4027 (1.3422)\tPrec @1 0.4531 (0.5306)\t\n",
      "Epoch: [7][80/391]\tTime 0.073 (0.074)\tLoss 1.3818 (1.3461)\tPrec @1 0.5547 (0.5282)\t\n",
      "Epoch: [7][90/391]\tTime 0.070 (0.074)\tLoss 1.3376 (1.3466)\tPrec @1 0.5312 (0.5288)\t\n",
      "Epoch: [7][100/391]\tTime 0.086 (0.075)\tLoss 1.3663 (1.3451)\tPrec @1 0.5469 (0.5282)\t\n",
      "Epoch: [7][110/391]\tTime 0.076 (0.075)\tLoss 1.4806 (1.3471)\tPrec @1 0.4766 (0.5277)\t\n",
      "Epoch: [7][120/391]\tTime 0.074 (0.075)\tLoss 1.3506 (1.3464)\tPrec @1 0.5312 (0.5281)\t\n",
      "Epoch: [7][130/391]\tTime 0.071 (0.075)\tLoss 1.3833 (1.3497)\tPrec @1 0.5625 (0.5261)\t\n",
      "Epoch: [7][140/391]\tTime 0.074 (0.075)\tLoss 1.3331 (1.3482)\tPrec @1 0.5547 (0.5267)\t\n",
      "Epoch: [7][150/391]\tTime 0.087 (0.075)\tLoss 1.4497 (1.3485)\tPrec @1 0.4766 (0.5262)\t\n",
      "Epoch: [7][160/391]\tTime 0.075 (0.075)\tLoss 1.3004 (1.3499)\tPrec @1 0.5078 (0.5242)\t\n",
      "Epoch: [7][170/391]\tTime 0.074 (0.075)\tLoss 1.2786 (1.3470)\tPrec @1 0.6094 (0.5258)\t\n",
      "Epoch: [7][180/391]\tTime 0.071 (0.075)\tLoss 1.2728 (1.3461)\tPrec @1 0.5234 (0.5259)\t\n",
      "Epoch: [7][190/391]\tTime 0.070 (0.075)\tLoss 1.2962 (1.3463)\tPrec @1 0.5625 (0.5261)\t\n",
      "Epoch: [7][200/391]\tTime 0.075 (0.075)\tLoss 1.2894 (1.3454)\tPrec @1 0.5781 (0.5269)\t\n",
      "Epoch: [7][210/391]\tTime 0.069 (0.075)\tLoss 1.4190 (1.3465)\tPrec @1 0.4844 (0.5263)\t\n",
      "Epoch: [7][220/391]\tTime 0.074 (0.075)\tLoss 1.3211 (1.3470)\tPrec @1 0.4531 (0.5261)\t\n",
      "Epoch: [7][230/391]\tTime 0.063 (0.075)\tLoss 1.3951 (1.3473)\tPrec @1 0.5156 (0.5261)\t\n",
      "Epoch: [7][240/391]\tTime 0.074 (0.075)\tLoss 1.4709 (1.3469)\tPrec @1 0.4297 (0.5258)\t\n",
      "Epoch: [7][250/391]\tTime 0.073 (0.075)\tLoss 1.3828 (1.3467)\tPrec @1 0.5547 (0.5259)\t\n",
      "Epoch: [7][260/391]\tTime 0.073 (0.075)\tLoss 1.3589 (1.3463)\tPrec @1 0.5859 (0.5261)\t\n",
      "Epoch: [7][270/391]\tTime 0.074 (0.075)\tLoss 1.3543 (1.3466)\tPrec @1 0.5781 (0.5264)\t\n",
      "Epoch: [7][280/391]\tTime 0.073 (0.075)\tLoss 1.3975 (1.3487)\tPrec @1 0.5156 (0.5253)\t\n",
      "Epoch: [7][290/391]\tTime 0.073 (0.075)\tLoss 1.2291 (1.3496)\tPrec @1 0.6328 (0.5249)\t\n",
      "Epoch: [7][300/391]\tTime 0.075 (0.075)\tLoss 1.4275 (1.3493)\tPrec @1 0.4922 (0.5248)\t\n",
      "Epoch: [7][310/391]\tTime 0.081 (0.075)\tLoss 1.4269 (1.3488)\tPrec @1 0.4922 (0.5248)\t\n",
      "Epoch: [7][320/391]\tTime 0.072 (0.075)\tLoss 1.3138 (1.3481)\tPrec @1 0.5312 (0.5251)\t\n",
      "Epoch: [7][330/391]\tTime 0.065 (0.075)\tLoss 1.2495 (1.3486)\tPrec @1 0.6016 (0.5255)\t\n",
      "Epoch: [7][340/391]\tTime 0.080 (0.075)\tLoss 1.3894 (1.3504)\tPrec @1 0.4922 (0.5251)\t\n",
      "Epoch: [7][350/391]\tTime 0.070 (0.075)\tLoss 1.4122 (1.3519)\tPrec @1 0.5156 (0.5245)\t\n",
      "Epoch: [7][360/391]\tTime 0.083 (0.075)\tLoss 1.2864 (1.3517)\tPrec @1 0.5469 (0.5244)\t\n",
      "Epoch: [7][370/391]\tTime 0.063 (0.075)\tLoss 1.3547 (1.3513)\tPrec @1 0.4922 (0.5247)\t\n",
      "Epoch: [7][380/391]\tTime 0.075 (0.075)\tLoss 1.4013 (1.3517)\tPrec @1 0.5156 (0.5244)\t\n",
      "Epoch: [7][390/391]\tTime 0.055 (0.075)\tLoss 1.4655 (1.3521)\tPrec @1 0.4750 (0.5244)\t\n",
      "Epoch: [7][0/100]\tTime 0.169 (0.169)\t\n",
      "Epoch: [7][10/100]\tTime 0.094 (0.103)\t\n",
      "Epoch: [7][20/100]\tTime 0.095 (0.102)\t\n",
      "Epoch: [7][30/100]\tTime 0.087 (0.102)\t\n",
      "Epoch: [7][40/100]\tTime 0.113 (0.100)\t\n",
      "Epoch: [7][50/100]\tTime 0.104 (0.100)\t\n",
      "Epoch: [7][60/100]\tTime 0.098 (0.100)\t\n",
      "Epoch: [7][70/100]\tTime 0.121 (0.099)\t\n",
      "Epoch: [7][80/100]\tTime 0.095 (0.099)\t\n",
      "Epoch: [7][90/100]\tTime 0.107 (0.099)\t\n",
      "Accuracy of Class 0: 0.5040\n",
      "Accuracy of Class 1: 0.6020\n",
      "Accuracy of Class 2: 0.3590\n",
      "Accuracy of Class 3: 0.2050\n",
      "Accuracy of Class 4: 0.3210\n",
      "Accuracy of Class 5: 0.6230\n",
      "Accuracy of Class 6: 0.7600\n",
      "Accuracy of Class 7: 0.5330\n",
      "Accuracy of Class 8: 0.7060\n",
      "Accuracy of Class 9: 0.5380\n",
      "* Prec @1: 0.5151\n",
      "Epoch: [8][0/391]\tTime 0.103 (0.103)\tLoss 1.4271 (1.4271)\tPrec @1 0.4609 (0.4609)\t\n",
      "Epoch: [8][10/391]\tTime 0.076 (0.079)\tLoss 1.2359 (1.3556)\tPrec @1 0.5859 (0.5213)\t\n",
      "Epoch: [8][20/391]\tTime 0.074 (0.076)\tLoss 1.3434 (1.3557)\tPrec @1 0.5859 (0.5253)\t\n",
      "Epoch: [8][30/391]\tTime 0.075 (0.075)\tLoss 1.4881 (1.3573)\tPrec @1 0.4375 (0.5209)\t\n",
      "Epoch: [8][40/391]\tTime 0.069 (0.075)\tLoss 1.3096 (1.3514)\tPrec @1 0.5781 (0.5191)\t\n",
      "Epoch: [8][50/391]\tTime 0.072 (0.074)\tLoss 1.4501 (1.3510)\tPrec @1 0.5391 (0.5195)\t\n",
      "Epoch: [8][60/391]\tTime 0.070 (0.074)\tLoss 1.3604 (1.3490)\tPrec @1 0.5078 (0.5196)\t\n",
      "Epoch: [8][70/391]\tTime 0.072 (0.074)\tLoss 1.4127 (1.3475)\tPrec @1 0.5156 (0.5201)\t\n",
      "Epoch: [8][80/391]\tTime 0.073 (0.074)\tLoss 1.3158 (1.3468)\tPrec @1 0.5078 (0.5202)\t\n",
      "Epoch: [8][90/391]\tTime 0.077 (0.074)\tLoss 1.2324 (1.3457)\tPrec @1 0.5938 (0.5232)\t\n",
      "Epoch: [8][100/391]\tTime 0.073 (0.074)\tLoss 1.3138 (1.3452)\tPrec @1 0.5859 (0.5258)\t\n",
      "Epoch: [8][110/391]\tTime 0.073 (0.074)\tLoss 1.3233 (1.3473)\tPrec @1 0.5000 (0.5253)\t\n",
      "Epoch: [8][120/391]\tTime 0.075 (0.074)\tLoss 1.3463 (1.3458)\tPrec @1 0.5234 (0.5255)\t\n",
      "Epoch: [8][130/391]\tTime 0.073 (0.074)\tLoss 1.4037 (1.3463)\tPrec @1 0.4844 (0.5256)\t\n",
      "Epoch: [8][140/391]\tTime 0.073 (0.074)\tLoss 1.3166 (1.3465)\tPrec @1 0.5156 (0.5259)\t\n",
      "Epoch: [8][150/391]\tTime 0.072 (0.074)\tLoss 1.2834 (1.3479)\tPrec @1 0.5312 (0.5244)\t\n",
      "Epoch: [8][160/391]\tTime 0.073 (0.074)\tLoss 1.4361 (1.3467)\tPrec @1 0.5156 (0.5247)\t\n",
      "Epoch: [8][170/391]\tTime 0.072 (0.074)\tLoss 1.4298 (1.3491)\tPrec @1 0.4688 (0.5228)\t\n",
      "Epoch: [8][180/391]\tTime 0.071 (0.074)\tLoss 1.3548 (1.3491)\tPrec @1 0.5391 (0.5225)\t\n",
      "Epoch: [8][190/391]\tTime 0.071 (0.074)\tLoss 1.3742 (1.3508)\tPrec @1 0.4844 (0.5218)\t\n",
      "Epoch: [8][200/391]\tTime 0.071 (0.074)\tLoss 1.3333 (1.3487)\tPrec @1 0.5234 (0.5224)\t\n",
      "Epoch: [8][210/391]\tTime 0.071 (0.074)\tLoss 1.3067 (1.3479)\tPrec @1 0.5547 (0.5231)\t\n",
      "Epoch: [8][220/391]\tTime 0.072 (0.074)\tLoss 1.4162 (1.3496)\tPrec @1 0.5234 (0.5230)\t\n",
      "Epoch: [8][230/391]\tTime 0.084 (0.075)\tLoss 1.4588 (1.3504)\tPrec @1 0.5156 (0.5233)\t\n",
      "Epoch: [8][240/391]\tTime 0.067 (0.075)\tLoss 1.3208 (1.3507)\tPrec @1 0.5391 (0.5228)\t\n",
      "Epoch: [8][250/391]\tTime 0.074 (0.075)\tLoss 1.3853 (1.3503)\tPrec @1 0.5000 (0.5229)\t\n",
      "Epoch: [8][260/391]\tTime 0.091 (0.075)\tLoss 1.2388 (1.3504)\tPrec @1 0.5469 (0.5228)\t\n",
      "Epoch: [8][270/391]\tTime 0.093 (0.076)\tLoss 1.2668 (1.3487)\tPrec @1 0.5469 (0.5238)\t\n",
      "Epoch: [8][280/391]\tTime 0.097 (0.076)\tLoss 1.2862 (1.3471)\tPrec @1 0.5859 (0.5248)\t\n",
      "Epoch: [8][290/391]\tTime 0.061 (0.077)\tLoss 1.3763 (1.3477)\tPrec @1 0.5078 (0.5241)\t\n",
      "Epoch: [8][300/391]\tTime 0.059 (0.077)\tLoss 1.2571 (1.3473)\tPrec @1 0.5625 (0.5240)\t\n",
      "Epoch: [8][310/391]\tTime 0.083 (0.077)\tLoss 1.2396 (1.3485)\tPrec @1 0.5234 (0.5231)\t\n",
      "Epoch: [8][320/391]\tTime 0.062 (0.077)\tLoss 1.4266 (1.3480)\tPrec @1 0.4688 (0.5225)\t\n",
      "Epoch: [8][330/391]\tTime 0.072 (0.077)\tLoss 1.3147 (1.3468)\tPrec @1 0.5625 (0.5233)\t\n",
      "Epoch: [8][340/391]\tTime 0.076 (0.076)\tLoss 1.2838 (1.3464)\tPrec @1 0.5938 (0.5241)\t\n",
      "Epoch: [8][350/391]\tTime 0.078 (0.076)\tLoss 1.4042 (1.3471)\tPrec @1 0.4453 (0.5237)\t\n",
      "Epoch: [8][360/391]\tTime 0.077 (0.076)\tLoss 1.4504 (1.3473)\tPrec @1 0.5000 (0.5241)\t\n",
      "Epoch: [8][370/391]\tTime 0.072 (0.076)\tLoss 1.3917 (1.3476)\tPrec @1 0.5469 (0.5243)\t\n",
      "Epoch: [8][380/391]\tTime 0.078 (0.076)\tLoss 1.4536 (1.3482)\tPrec @1 0.4375 (0.5239)\t\n",
      "Epoch: [8][390/391]\tTime 0.056 (0.076)\tLoss 1.3640 (1.3476)\tPrec @1 0.5750 (0.5248)\t\n",
      "Epoch: [8][0/100]\tTime 0.194 (0.194)\t\n",
      "Epoch: [8][10/100]\tTime 0.103 (0.112)\t\n",
      "Epoch: [8][20/100]\tTime 0.105 (0.105)\t\n",
      "Epoch: [8][30/100]\tTime 0.103 (0.103)\t\n",
      "Epoch: [8][40/100]\tTime 0.097 (0.101)\t\n",
      "Epoch: [8][50/100]\tTime 0.095 (0.100)\t\n",
      "Epoch: [8][60/100]\tTime 0.092 (0.099)\t\n",
      "Epoch: [8][70/100]\tTime 0.091 (0.099)\t\n",
      "Epoch: [8][80/100]\tTime 0.104 (0.099)\t\n",
      "Epoch: [8][90/100]\tTime 0.095 (0.099)\t\n",
      "Accuracy of Class 0: 0.5160\n",
      "Accuracy of Class 1: 0.5820\n",
      "Accuracy of Class 2: 0.3610\n",
      "Accuracy of Class 3: 0.2140\n",
      "Accuracy of Class 4: 0.3220\n",
      "Accuracy of Class 5: 0.6320\n",
      "Accuracy of Class 6: 0.7340\n",
      "Accuracy of Class 7: 0.5520\n",
      "Accuracy of Class 8: 0.7190\n",
      "Accuracy of Class 9: 0.5440\n",
      "* Prec @1: 0.5176\n",
      "Epoch: [9][0/391]\tTime 0.100 (0.100)\tLoss 1.3390 (1.3390)\tPrec @1 0.5156 (0.5156)\t\n",
      "Epoch: [9][10/391]\tTime 0.071 (0.079)\tLoss 1.3763 (1.3393)\tPrec @1 0.5000 (0.5291)\t\n",
      "Epoch: [9][20/391]\tTime 0.069 (0.077)\tLoss 1.4647 (1.3645)\tPrec @1 0.4375 (0.5097)\t\n",
      "Epoch: [9][30/391]\tTime 0.078 (0.076)\tLoss 1.5216 (1.3603)\tPrec @1 0.4219 (0.5171)\t\n",
      "Epoch: [9][40/391]\tTime 0.073 (0.075)\tLoss 1.2427 (1.3588)\tPrec @1 0.5938 (0.5175)\t\n",
      "Epoch: [9][50/391]\tTime 0.076 (0.075)\tLoss 1.5287 (1.3645)\tPrec @1 0.4375 (0.5164)\t\n",
      "Epoch: [9][60/391]\tTime 0.077 (0.075)\tLoss 1.2734 (1.3618)\tPrec @1 0.5000 (0.5155)\t\n",
      "Epoch: [9][70/391]\tTime 0.077 (0.075)\tLoss 1.3811 (1.3567)\tPrec @1 0.5078 (0.5174)\t\n",
      "Epoch: [9][80/391]\tTime 0.074 (0.075)\tLoss 1.2643 (1.3543)\tPrec @1 0.6172 (0.5202)\t\n",
      "Epoch: [9][90/391]\tTime 0.075 (0.075)\tLoss 1.3539 (1.3537)\tPrec @1 0.5000 (0.5182)\t\n",
      "Epoch: [9][100/391]\tTime 0.075 (0.075)\tLoss 1.3080 (1.3531)\tPrec @1 0.5391 (0.5203)\t\n",
      "Epoch: [9][110/391]\tTime 0.071 (0.074)\tLoss 1.2814 (1.3518)\tPrec @1 0.5938 (0.5214)\t\n",
      "Epoch: [9][120/391]\tTime 0.072 (0.075)\tLoss 1.3444 (1.3503)\tPrec @1 0.5469 (0.5218)\t\n",
      "Epoch: [9][130/391]\tTime 0.072 (0.074)\tLoss 1.2490 (1.3475)\tPrec @1 0.5859 (0.5233)\t\n",
      "Epoch: [9][140/391]\tTime 0.071 (0.074)\tLoss 1.3355 (1.3492)\tPrec @1 0.5469 (0.5231)\t\n",
      "Epoch: [9][150/391]\tTime 0.071 (0.074)\tLoss 1.4655 (1.3485)\tPrec @1 0.5469 (0.5228)\t\n",
      "Epoch: [9][160/391]\tTime 0.074 (0.074)\tLoss 1.3723 (1.3466)\tPrec @1 0.4766 (0.5247)\t\n",
      "Epoch: [9][170/391]\tTime 0.070 (0.074)\tLoss 1.1967 (1.3462)\tPrec @1 0.5938 (0.5248)\t\n",
      "Epoch: [9][180/391]\tTime 0.070 (0.074)\tLoss 1.3868 (1.3467)\tPrec @1 0.5781 (0.5248)\t\n",
      "Epoch: [9][190/391]\tTime 0.071 (0.074)\tLoss 1.4620 (1.3475)\tPrec @1 0.4844 (0.5249)\t\n",
      "Epoch: [9][200/391]\tTime 0.072 (0.074)\tLoss 1.2494 (1.3459)\tPrec @1 0.5234 (0.5256)\t\n",
      "Epoch: [9][210/391]\tTime 0.071 (0.074)\tLoss 1.3987 (1.3453)\tPrec @1 0.4766 (0.5253)\t\n",
      "Epoch: [9][220/391]\tTime 0.073 (0.074)\tLoss 1.3218 (1.3445)\tPrec @1 0.5469 (0.5257)\t\n",
      "Epoch: [9][230/391]\tTime 0.071 (0.074)\tLoss 1.3944 (1.3446)\tPrec @1 0.5234 (0.5260)\t\n",
      "Epoch: [9][240/391]\tTime 0.073 (0.074)\tLoss 1.1728 (1.3434)\tPrec @1 0.5938 (0.5265)\t\n",
      "Epoch: [9][250/391]\tTime 0.074 (0.074)\tLoss 1.3502 (1.3441)\tPrec @1 0.4766 (0.5263)\t\n",
      "Epoch: [9][260/391]\tTime 0.074 (0.074)\tLoss 1.3982 (1.3432)\tPrec @1 0.5234 (0.5274)\t\n",
      "Epoch: [9][270/391]\tTime 0.071 (0.074)\tLoss 1.3665 (1.3428)\tPrec @1 0.5156 (0.5278)\t\n",
      "Epoch: [9][280/391]\tTime 0.071 (0.074)\tLoss 1.3571 (1.3424)\tPrec @1 0.5938 (0.5280)\t\n",
      "Epoch: [9][290/391]\tTime 0.077 (0.075)\tLoss 1.4152 (1.3412)\tPrec @1 0.5000 (0.5279)\t\n",
      "Epoch: [9][300/391]\tTime 0.078 (0.075)\tLoss 1.3757 (1.3414)\tPrec @1 0.5312 (0.5276)\t\n",
      "Epoch: [9][310/391]\tTime 0.083 (0.075)\tLoss 1.3710 (1.3411)\tPrec @1 0.4844 (0.5277)\t\n",
      "Epoch: [9][320/391]\tTime 0.095 (0.076)\tLoss 1.3100 (1.3423)\tPrec @1 0.5234 (0.5272)\t\n",
      "Epoch: [9][330/391]\tTime 0.067 (0.076)\tLoss 1.4171 (1.3433)\tPrec @1 0.5234 (0.5265)\t\n",
      "Epoch: [9][340/391]\tTime 0.057 (0.076)\tLoss 1.3027 (1.3434)\tPrec @1 0.5312 (0.5265)\t\n",
      "Epoch: [9][350/391]\tTime 0.058 (0.076)\tLoss 1.2800 (1.3442)\tPrec @1 0.5469 (0.5260)\t\n",
      "Epoch: [9][360/391]\tTime 0.072 (0.076)\tLoss 1.3551 (1.3448)\tPrec @1 0.4375 (0.5256)\t\n",
      "Epoch: [9][370/391]\tTime 0.078 (0.076)\tLoss 1.3569 (1.3449)\tPrec @1 0.4922 (0.5252)\t\n",
      "Epoch: [9][380/391]\tTime 0.078 (0.076)\tLoss 1.4900 (1.3451)\tPrec @1 0.4922 (0.5251)\t\n",
      "Epoch: [9][390/391]\tTime 0.050 (0.076)\tLoss 1.2990 (1.3463)\tPrec @1 0.5125 (0.5247)\t\n",
      "Epoch: [9][0/100]\tTime 0.171 (0.171)\t\n",
      "Epoch: [9][10/100]\tTime 0.087 (0.110)\t\n",
      "Epoch: [9][20/100]\tTime 0.106 (0.104)\t\n",
      "Epoch: [9][30/100]\tTime 0.088 (0.102)\t\n",
      "Epoch: [9][40/100]\tTime 0.103 (0.102)\t\n",
      "Epoch: [9][50/100]\tTime 0.111 (0.101)\t\n",
      "Epoch: [9][60/100]\tTime 0.091 (0.102)\t\n",
      "Epoch: [9][70/100]\tTime 0.088 (0.102)\t\n",
      "Epoch: [9][80/100]\tTime 0.100 (0.101)\t\n",
      "Epoch: [9][90/100]\tTime 0.090 (0.101)\t\n",
      "Accuracy of Class 0: 0.5050\n",
      "Accuracy of Class 1: 0.6010\n",
      "Accuracy of Class 2: 0.3650\n",
      "Accuracy of Class 3: 0.2200\n",
      "Accuracy of Class 4: 0.3450\n",
      "Accuracy of Class 5: 0.6310\n",
      "Accuracy of Class 6: 0.7440\n",
      "Accuracy of Class 7: 0.5410\n",
      "Accuracy of Class 8: 0.7070\n",
      "Accuracy of Class 9: 0.5350\n",
      "* Prec @1: 0.5194\n",
      "Best Prec @1 Acccuracy: 0.5194\n",
      "Accuracy of Class 0: 0.5050\n",
      "Accuracy of Class 1: 0.6010\n",
      "Accuracy of Class 2: 0.3650\n",
      "Accuracy of Class 3: 0.2200\n",
      "Accuracy of Class 4: 0.3450\n",
      "Accuracy of Class 5: 0.6310\n",
      "Accuracy of Class 6: 0.7440\n",
      "Accuracy of Class 7: 0.5410\n",
      "Accuracy of Class 8: 0.7070\n",
      "Accuracy of Class 9: 0.5350\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zWfbgzB4Uiu"
   },
   "source": "`Let's test your models implementation. **Make sure to train your models and create checkpoints before running the following tests**."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Db0t0IChKK0h"
   },
   "source": [
    "#Let's test your implementation of two layer\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_twolayer.py'}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X97MN9JvcMQY"
   },
   "source": [
    "#Let's test your implementation of my_model\n",
    "!pytest -s { GOOGLE_DRIVE_PATH + '/tests/test_mymodel.py'}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zaXbxcApKPNw"
   },
   "source": [
    "#Let's test your implementation of Vanilla CNN\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_vanilla_cnn.py'}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D68rtzAZpzgc"
   },
   "source": [
    "# Data Wrangling\n",
    "So far we have worked with well-balanced datasets (samples of each class are\n",
    "evenly distributed). However, in practice, datasets are often not balanced.\n",
    "In this section, you will explore the limitation of standard training strategy\n",
    "on this type of dataset. This being an exploration, it is up to you to design\n",
    "experiments or tests to validate these methods are correct and effective.\n",
    "You will work with an unbalanced version of CIFAR-10 in this section, and you should use the ResNet-32 model in `./models/resnet.py`.\n",
    "\n",
    "## Class-Balanced Focal Loss\n",
    "You will implement one possible solution to the imbalance problem: ClassBalanced Focal Loss using this CVPR-19 paper [Class-Balanced Loss Based on Effective Number of Samples](https://arxiv.org/pdf/1901.05555.pdf). You may also refer to the original paper of [Focal Loss](https://arxiv.org/abs/1708.02002) for more details if you are interested. Please implement CB Focal\n",
    "Loss in `./losses/focal_loss.py`.\n",
    "\n",
    "**Note**: The CVPR-19 paper uses Sigmoid̲ CB focal loss (section 4). Softmax CB focal loss is not described in the paper, but it is easy to derive from the mentioned papers. You must implement the softmax version to pass the\n",
    "tests.\n",
    "\n",
    "Hint: Make sure you are using torch operations througout your focal loss implementation otherwise the torch computation graph will not be built properly."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FUEYEuHBpzgd"
   },
   "source": [
    "# Test your Focal Loss implementation\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_focalloss.py'}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, follow the instructions in the report template to obtain the best results possible for Resnet with regular CE loss (you may need to perform extra hyperparameter tuning). Then experiment with the beta parameter. Finally,  obtain the best possible results for Resnet using focal loss. You are welcome to change other hyperparameters in the config file as necessary. Make sure to set the `imbalance` config parameter as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjZK5lqLFsor"
   },
   "source": [
    "# Submit Your Work\n",
    "After completing the notebook for this assignment (`assignment2_2.ipynb`), run the following cell to create a `.zip` file for you to download and then upload to Gradescope.\n",
    "\n",
    "**Please MANUALLY SAVE `*.py` files before executing the following cell:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uPREUKv7FwPS"
   },
   "source": [
    "from cs7643.submit import make_a2_2_submission\n",
    "\n",
    "make_a2_2_submission(GOOGLE_DRIVE_PATH)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
